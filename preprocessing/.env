--- Configuración para el LLM Local ---
Define el proveedor a usar: "local" para tu servidor, "openai" para la API de OpenAI.
LLM_PROVIDER="local"

URL base de tu servidor local
LLM_BASE_URL="http://10.6.125.217:8080/v1"

Nombre del modelo de embeddings que quieres usar en tu servidor local
EMBEDDING_MODEL="text-embedding-nomic-embed-text-v2-moe"

--- Configuración para OpenAI (no se usará si LLM_PROVIDER es "local") ---
OPENAI_API_KEY="sk-..."